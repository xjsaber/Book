# Java并发编程实战 #

# 开篇词 #

## 开篇词 | 你为什么需要学习并发编程？ ##

并发编程可以总结为三个核心问题：分工、同步、互斥

* 分工：如何高效地拆解任务并分配给线程
* 同步：线程之间如合协作
* 互斥：保证同一时刻只允许一个线程访问资源

JDK并发包是按照这三个维度组织的，Fork/Join框架是一种分工模式，CountDownLatch是一种同步方式，可重入锁则是一种互斥手段。

# 学习攻略|如何才能学好并发编程 #

## 学习攻略 | 如何才能学好并发编程？ ##

其实并发编程可以总结为三个核心问题：分工，同步，互斥

### 1. 分工 ###

### 2. 同步 ###

一个线程执行完了一个任务，如何通知执行后续任务的线程开工

协作一般是和分工相关。JDK并发包里的Executor、Fork/Join、Future本质都是分工方法，但同时也能解决线程协作的问题。

在Java并发编程领域，解决协作问题的核心技术是**管程**

管程是解决并发问题的万能钥匙。

### 3. 互斥 ###

并发程序里，当多个线程同时访问同一个共享变量的时候，结果是不确定的。不确定，意味着可能正确，也可能错误。

不确定的主要源头是可见性问题、有序性问题和原子性问题。为了解决这三个问题，Java语言引入了内存模型，内存模型提供了一系列规则， 利用这些规则，可以避免可见性问题、有序性问题，但还是不足以完全解决线程安全问题。解决线程安全问题的核心方案还是互斥。

#### 所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。 ####

实现互斥的核心技术就是锁，Java语言里synchronized、SDK里的各种Lock都能解决互斥问题。

#### 钻进去，看本质 ####

工程商的解决方案，一定要有理论做基础。

### 总结 ###

![11e0c64618c04edba52619f41aaa3565.png](/img/11e0c64618c04edba52619f41aaa3565.png)

# 第一部分：并发理论基础 #

## 01 | 可见性、原子性和有序性问题：并发编程Bug的源头 ##

### 并发程序幕后的故事 ###

核心矛盾一直存在，就是CPU、内存、I/O设备三者的速度差异。

1. CPU增加了缓存，以均衡与内存的速度差异；
2. 操作系统增加了进程、线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异；
3. 编译程序优化指令执行时序，使得缓存能够得到更加合理地利用；

### 源头之一：缓存导致的可见性问题 ###

一个线程对共享变量的修改，另外一个线程能够立刻看到，我们成为**可见性**

### 源头之二：线程切换带来的原子性问题 ###

操作系统允许某个进程执行一小段时间，例如50毫秒，过了50毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个50毫秒称为“时间片”。（在一个时间片内，如果一个进程进行IO操作，例如读个文件，这个时候该进程就可以把自己标记为“休眠状态”并且让出CPU使用权，待文件读进内存，操作系统会把休眠的进程唤醒，唤醒后的进程有机会重新获得CPU的使用权）

早期的操作系统基于进程来调度CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都共享一个内存空间的，所以线程切换成本更低。“任务切换”就是“线程切换”

多条CPU指令

count += 1，至少
1. 首先，需要把变量count从内存加载到CPU的寄存器；
2. 之后，再寄存器中执行+1操作；
3. 最后，将结果写入到内存（缓存机制导致可能写入的是CPU缓存而不是内存）

操作系统做任务切换，可以发生在任何一条**CPU指令**执行完，如果线程A在指令1执行完后做线程切换，线程A和线程B按照

我们把一个后者多个操作在CPU执行的过程不被中断的特性称为原子性

### 源头之三：编译优化带来的有序性问题 ###

双重检查创建单例对象，在获取实例getInstance()的方法中，我们首先判断instance是否为空，则锁定Singleton.class并再次检查isntance是否为空，如果为空则创建Singleton的一个实例。

	public class Singleton {
	  static Singleton instance;
	  static Singleton getInstance(){
	    if (instance == null) {
	      synchronized(Singleton.class) {
	        if (instance == null)
	          instance = new Singleton();
	        }
	    }
	    return instance;
	  }
	}

1. 分配一块内存M；
2. 在内存M上初始化Singleton对象；
3. 然后M的地址赋值给instance变量。

优化后的执行路径是：

1. 分配一块内存M；
2. 将M的地址赋值给instance变量；
3. 最后在内存M上初始化Singleton对象；

![64c955c65010aae3902ec918412827d8.png](img/64c955c65010aae3902ec918412827d8.png)

### 总结 ###

只要我们能够深刻理解可见性、原子性、有序性在并发场景下的原理，很多并发Bug都是可以理解、可以诊断的。

* 缓存：可见性问题
* 线程切换：原子性问题
* 编译优化：有序性问题

在采用一项技术的同时，一定要清除它带来的问题是什么，以及如何规避。

寄存器是共用的，A线程切换到B线程的时候，寄存器把操作A的相关内容会保存到内存中，切换回来的时候，会从内存把内容加载到寄存器。可以理解为每个线程都有自己的寄存器。

### 课后思考 ###

常听人说，在 32 位的机器上对 long 型变量进行加减操作存在并发隐患，到底是不是这样呢？现在相信你一定能分析出来。

long型变量表示64位，在32位机器上，需要对long型变量进行加减操作的时候，需要时间片切换，引发原子性问题（线程切换带来的原子性问题）

## 02 | Java内存模型：看Java如何解决可见性和有序性问题 ##

### 什么是Java内存模型？ ###

禁用缓存和编译优化

合理的方案应该是按需禁用缓存以及编译优化

volatile、synchronized和final

### 使用volatile的困惑 ###

### Happens-Before规则 ###

前面一个操作的结果对后面操作是可见的。Happens-Before规则就是要保证线程之间的这种“心灵感应”。——Happens-Before

#### 1. 程序的顺序性规则 ####

#### 2. volatile变量规则 ####

对一个volatile变量的写操作相对于后续对这个volatile变量的读操作可见。

#### 3. 传递性 ####

A Happens-Before B，且B Happens-Before C，那么A Happens-Before C

* “x=42” Happens-Before写变量“v=true”，这是规则1的内容
* 写变量“v=true”Happens-Before读变量“v=true”，这是规则2的内容

#### 4. 官程中锁的规则 ####

Happens-Before于后续读这个锁的加锁

管程是一种通用的同步原语，在Java中指的是synchronized，synchronized是Java里对管程的实现。管程中的锁在Java里是隐式实现的。

	synchronzied (this) { // 此处自动加锁
		// x是共享变量，初始值=10
		if (this.x < 12) {
			this.x = 12;
		}
	} // 此处自动解锁

#### 5. 线程start()规则 ####

关于线程启动，指主线程A启动子线程B，子线程B能够看到主线程在启动子线程B前的操作。

如果线程A调用线程B的start()方法（即在线程A中启动线程B），那么该start()操作Happens-Before于线程B中的任意操作。

	Thread B = new Thread(() -> {
		// 主线程调用B.start()之前
		// 所有对共享变量的修改，此处皆可见
		// 此例中，var == 77
	})
	// 此处

#### 6. 线程join()规则 ####

线程等待的，它是指主线程A等待子线程B完成（主线程A通过调用子线程B的join()方法实现），当子线程B完成后（主线程A中join()方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对**共享变量**的操作。

如果在线程A中，调用线程B的join()并成功返回

### 被我们忽视的final ###

final修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲优化。

### 总结 ###

Time，Clocks，and the Ordering of Events is a Distributed System

在Java语言里面，Happens-Before的语义本质上是一种可见性，A Happens-Before B意味着A事件对B事件来说是可见得，无论A事件和B事件是否发生在同一个线程里。

### 课后思考 ###

有一个共享变量abc，在一个线程里设置了abc的值abc=3，有哪些办法可以让其他线程能够看到abc==3？

	final int abc = 3;
	volatile int abc = 3;
	synchronized int abc = 3;

## 03 | 互斥锁（上）：解决原子性 ##

#### 那原子性问题到底如何解决呢？ ####

原子性问题的源头是**线程切换**

操作系统做线程切换是依赖CPU中断的，所以禁止CPU发生中断就能够禁止线程切换。

“同一时刻只有一个线程执行”，“互斥”。能够对共享变量的修改是互斥的，无论是单核CPU还是多核CPU，都能保证原子性。
### 简易锁模型 ###

线程在进入临界区之前，首先尝试加锁lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则就等待，直到持有锁的线程解锁；持有锁的线程执行完成临界区的代码后，执行解锁unlock()。

### 改进后的锁模型 ###

要保护资源R就得为它创建一把锁LR。针对这把锁LR，需要在进出临界区时添加锁操作和解锁操作。另外，在锁LR和受保护资源之间，特地用一条线做了关联，这个关联关联非常重要。很多并发

### Java语言提供的锁技术：synchronized ###

	class X {
		synchronzied void foo() {
			//临界区
		}
		// 修饰静态方法
		synchronized static void bar() {
			//临界区
		}
		// 修饰代码块
		Object obj = new Object();
		void baz() {
			synchronzied(obj){
				// 临界区
			}
		}
	}

#### 用synchronized解决count += 1问题 ####

### 锁和受保护资源的关系 ###

### 总结 ###

synchronzied是Java在语言层面提供的互斥原语，其实Java里面还有很多其他类型的锁，但作为互斥锁，原理都是想通的：锁，一定要有一个要锁定的


## 04 | 互斥锁（下）：如何用一把锁保护多个资源 ##

受保护资源和锁之间合理的关联关系是N：1的关系。（可以用一把锁来保护多个资源，但是不能用多个锁来保护一个资源）

### 保护没有关联关系的多个资源 ###

用不同的锁对受保护资源进行精细化管理，能够提升性能。

细粒度锁。

### 保护有关联关系的多个资源 ###

### 使用锁的正确姿势 ###

锁能覆盖所有受保护资源

用Account.class作为共享的锁

### 总结 ###

“原子性”的本质是什么？其实不是不可分割，不可分割只是外在表现，其本质是多个资源间

## 05 | 一不小心就死锁了，怎么办？ ##



## 06 | 用“等待-通知”机制优化循环等待 ##

等待-通知机制

### 尽量使用 notifyAll() ###

### 总结 ###

synchronized 配合 wait()、notify...

### 课后思考 ###

wait()方法和sleep()方法

# 07 | 安全性、活跃性以及性能问题 #

### 安全性问题 ###

锁

### 活跃性问题 ###

死锁，活锁和饥饿

### 性能问题 ###

### 总结 ###

* 微观上涉及到原子性问题、可见性问题和有序性问题
* 宏观则表现为安全性、活跃性以及性能问题

### 课后思考 ###


# 08 | 管程：并发编程的万能钥匙 #

### 什么是管程 ###

管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。

管程：指的是管理共享变量以及共享变量的操作过程，让他们支持并发。

### MESA模型 ###

管程的发展史：

1. Hasen模型
2. Hoare模型
3. MESA模型

# 08 | 管程：并发编程的万能钥匙 #

# 09 | Java线程（上）：Java线程的生命周期 #

### 通用的线程生命周期 ###

### Java中线程的生命周期 ###

1. NEW（初始化状态）
2. RUNNABLE（可运行/运行状态）
3. BLOCKED（阻塞状态）
4. WAITING（无时限等待）
5. TIMED_WAITING（有时限等待）
6. TERMINATED（终止状态）

#### 1. RUNNABLE与BLOCKED的状态转换 ####

#### 2. RUNNABLE与WAITING的状态转换 ####

#### 3. RUNNABLE与TIMED_WAITING的状态转换 ####

1. 调用带超时参数的Thread.sleep(long millis)方法；
2. 获得synchronized隐式锁的线程，调用带超时参数的Object.wait(long timeout)方法
3. 调用带超时参数的Thread.join(long millis)方法；
4. 调用带超时参数的LockSupport.parkNanos(Object blocker, long deadline)方法；
5. 调用带超时参数的LockSupport.partUntil(long deadline)方法。

#### 4. 从NEW到RUNNABLE状态 ####

#### 5. 从RUNNABLE到TERMINATED状态 ####

* stop()
* interrupt()

### 总结 ###

### 课后思考 ###

# 10 | Java线程（中）：创建多少线程才是合适的？ #

### 为什么要使用多线程？ ###

延迟和吞吐量

### 多线程的应用场景 ###

### 创建多少线程合适？ ###



### 总结 ###

将硬件的性能发挥到极致

### 课后思考 ###



# 11 | Java线程（下）：为什么局部变量是线程安全的？ #

### 方法是如何被执行 ###

通过CPU的堆栈寄存器。CPU支持一种栈结构。因为栈和方法调用相关，因此被称为调用栈。

每个方法在调用栈里都有自己的独立空间，称为帧栈。每个栈帧里都有对应方法需要的参数和返回地址。当调用方法时，会创建新的栈帧，并压入调用栈；当方法返回时，对应的栈帧就会被自动弹出。也就是说，栈帧和方法是同生同死的。

Java语言虽然是靠虚拟机解释执行的，但是方法调用也是利用栈结构解决的。

### 局部变量存哪里？ ###

局部变量的作用域是方法内部，也就是说方法执行完，局部变量就没用了，局部变量和方法应该同生共死。调用栈的栈帧就是和方法同生共死的，所以局部变量放到调用栈那儿是相当的合理。

局部变量就是放到调用栈里的。

局部变量和方法同生共死的，一个变量如果想要跨越方法的边界，就必须创建在堆中。

### 调用栈与线程 ###

每个线程都有自己独立的调用栈。

Java方法里面的局部变量是否存在并发问题？一点问题都没有，因为每个线程都有自己的调用栈，局部变量保存在线程各自的调用栈里面，不会共享，所以自然也就没有并发问题。

没有共享，就没有伤害。

### 线程封闭 ###

方法里的局部变量，因此不会和其他线程共享，所以没有并发问题。

线程封闭，仅在单线程内访问数据。

在JDBC规范里并没有要求这个Connection必须是线程安全的。数据库连接池通过线程封闭技术，保证一个Connection一旦被一个线程获取之后，在这个线程关闭Connection之前的这段时间里，不会再分配给其他线程，从而保证了Connection不会有并发问题。

### 总结 ###

研究原理性的东西、通用的东西。

### 课后思考 ###

常听人说，递归调用太深，可能导致栈溢出。

# 12 | 如何用面向思想写好并发程序？ #

在Java语言中，面向对象思想能够让并发编程变得更简单。

封装共享变量、识别共享变量间的约束条件和制定并发访问策略这三方面下手

### 一、封装共享变量 ###

面向对象思想里面有一个很重要的特性是**封装**，封装的通俗解释就是讲属性和实现细节封装在对象内部，外界对象只能通过目标对象提供的公共方法来间接访问这些属性。

利用面向对象思想写并发程序的思想，将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略

对于不会发生变化的共享变量，建议使用final关键字来修饰。

### 二、识别共享变量间的约束条件 ###

识别共享变量间的约束条件非常重要。因为这些约束条件，决定并发访问策略。

### 三、制定并发访问策略 ###

1. 避免共享：避免共享的技术主要是利于线程本地存储以及为每个任务分配独立的线程。
2. 不变模式：这个在Java领域应用的很少，但在其他领域却有着广泛的应用，例如Actor模式、CSP模式以及函数式编程的基础都是不变模式。
3. 管程及其他同步工具：Java领域万能的解决方案是管程，但是对于很多特定的场景，使用Java并发包提供的读写锁、并发容器等同步工具会更好。

### 总结 ###

利用面向对象思想编写并发程序

1. 利用面向对象里的封装特性
2. 面对共享变量进行封装，要避免“逸出”，所谓“逸出”就是共享变量逃逸到对象的外面。

### 课后思考 ###

类SafeVM不满足库存下限要小于库存上限这个约束条件，修改让它能够在并发条件下满足库存下限要小于库存上限这个约束条件

### 延伸阅读 ###

# 13 | 理论基础模块热点问题答疑 #

### 1. 用锁的最佳实践 ###

### 2. 锁的性能要看场景 ###

### 3. 竞态条件需要格外关注 ###

### 4. 方法调用是先计算参数 ###

### 5. InterruptedException异常处理需小心 ###

# 第二部分：并发工具类 #

# 14 | Lock和Condition（上）：隐藏在并发包中的管程 #

1. 互斥：同一时刻只允许一个线程访问共享资源。
2. 同步：线程之间如何通信、写作。

Java SDK并发包通过Lock和Condition两个接口来实现管程，其中Lock用于解决互斥问题，Condition用于解决同步问题。

### 再造管程的理由 ###

synchronized申请资源的时候，如果申请不到，线程直接进入阻塞状态，二线程进入阻塞状态，也释放不了线程已经占有的资源。

1. 能够响应中断。synchronized的问题是，持有锁A后，如果尝试获取锁B失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发生中断信号的时候，能够唤醒它，那么它就有机会释放曾经持有的锁A。这样就破坏了不可抢占条件了。
2. 支持超时。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经的持有的锁，这样也能破坏不可抢占条件。
3. 非阻塞地获取锁。如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。

	// 支持中断的API
	void lockInterruptibly() throws InterruputedException;
	// 支持超时的API
	boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
	// 支持非阻塞获取锁的API
	boolean tryLock();

### 如何保证可见性 ###

### 什么是可重入锁 ###

所谓可重入锁，顾名思义，指的是线程可以重复获取同一把锁。

### 公平锁与非公平锁 ###

在使用ReetrantLock时候，有两个构造函数，一个是无参构造函数，一个是传入fail参数的构造函数。fair参数代表的是锁的公平策略，如果传入true就标识需要构造一个公平锁，反之则表示要一个非公平锁。

	// 无参构造函数：默认非公平锁
	public ReetrantLock() {
		sync = new NonfairSync();
	}
	// 根据公平策略参数创建锁
	public ReetrantLock(boolean fair) {
		sync = fair ? new FairSync() : new NonfairSync();
	}
	
	
### 用锁的最佳实践 ###

Java并发编程：设计原则与模式

1. 永远只在更新对象的成员变量时加锁
2. 永远只在访问可变的成员变量时加锁
3. 永远不在调用其他对象的方法时加锁

### 总结 ###





# 15 | Lock和Conndition（下）：Dubbo如何用管程实现异步转同步 #

# 结束语 #

## 结束语 | 十年之后，初心依旧 ##




