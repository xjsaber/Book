# Java并发编程实战 #

# 开篇词 #

## 开篇词 | 你为什么需要学习并发编程？ ##

并发编程已经慢慢成为一项必备技能。

Java SDK并发包里的条件变量Condition也是管程里的概念。管程作为一种解决并发问题的模型，是继信号量之后的一项重大的创新，它与信号量在逻辑上是等价的（可以用管程实现信号量，也可以用信号量实现管程），但是相比之下管程更易用。很多人急于学习Java并发编程技术，却忽略了技术背后的理论和模型，而理论和模型却往往比具体的技术更为重要。

并发编程可以总结为三个核心问题：分工、同步、互斥

* 分工：如何高效地拆解任务并分配给线程
* 同步：线程之间如合协作
* 互斥：保证同一时刻只允许一个线程访问资源

JDK并发包是按照这三个维度组织的，Fork/Join框架是一种分工模式，CountDownLatch是一种同步方式，可重入锁则是一种互斥手段。

并发编程并不是Java特有的语言特性，它是一个通用且早已成熟的领域。Java只是根据自身情况做了实现罢了，当你理解或学习并发编程的时候，如果能够站在较高层面，系统且有体系地思考问题，那就会容易很多。

坚持！

### 精选留言 ###

* 并发编程实战
* 实战java虚拟机
* 操作系统：精髓与设计原理

如果学原理的话，可以参考

* 计算机的心智-操作系统之哲学原理
* 操作系统精髓与设计原理
如果想深入学，可以看

* unix操作系统设计
* 还可以看看linux 0.11的源代码

* Q: 老师， 想请教一下线上多线程的问题怎么查找，jstack怎么判断出锁的问题？
遇到个问题：有一个接收客户端请求的服务（接收到请求然后做相应的调度执行，异步执行完后返回结果）， 运行几天 提交的请求都不调度了，内存gc都正常，cpu负载很低， 这种问题要怎么入手查找？
* A: 作者回复: 给工作线程设置特殊的名字，查看它们在干嘛，简单的死锁是可以检测出来的，复杂的问题只能靠经验，还有些在线诊断工具，比如arthas

* Q: 比如我用的tomcat，当访问量从1到一定的范围内(如200)，响应的效率没有明显的差距，都在1秒以内，可是再往上，响应时间就会一下子到好几秒，如果达到400，就经常出现无响应，请教这到底都受到哪些因素的影响，底层的原理是什么
* A: 作者回复: 这个要看瓶颈在哪里。线程多了增加了线程的切换成本，不是说线程多了就跑得快。有可能cpu是瓶颈，也有可能IO设备是瓶颈，也有可能是依赖的第三方服务扛不住了，比如数据库扛不住。理论上响应时间和并发量也不是线性关系。这个只能具体问题具体分析。

* Q:有根据场景讲如何设计运用这些并发工具
* A:入门的话，可以看看《图解Java多线程设计模式》

# 学习攻略|如何才能学好并发编程 #

## 学习攻略 | 如何才能学好并发编程？ ##

其实并发编程可以总结为三个核心问题：分工，同步，互斥

### 1. 分工 ###

### 2. 同步 ###

一个线程执行完了一个任务，如何通知执行后续任务的线程开工

协作一般是和分工相关。JDK并发包里的Executor、Fork/Join、Future本质都是分工方法，但同时也能解决线程协作的问题。

在Java并发编程领域，解决协作问题的核心技术是**管程**

管程是解决并发问题的万能钥匙。

### 3. 互斥 ###

并发程序里，当多个线程同时访问同一个共享变量的时候，结果是不确定的。不确定，意味着可能正确，也可能错误。

不确定的主要源头是可见性问题、有序性问题和原子性问题。为了解决这三个问题，Java语言引入了内存模型，内存模型提供了一系列规则， 利用这些规则，可以避免可见性问题、有序性问题，但还是不足以完全解决线程安全问题。解决线程安全问题的核心方案还是互斥。

#### 所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。 ####

实现互斥的核心技术就是锁，Java语言里synchronized、SDK里的各种Lock都能解决互斥问题。

#### 钻进去，看本质 ####

工程商的解决方案，一定要有理论做基础。

### 总结 ###

![11e0c64618c04edba52619f41aaa3565.png](/img/11e0c64618c04edba52619f41aaa3565.png)

试图上来就看Java SDK的并发包，但眼花缭乱，借助网络上的技术文章，感觉看的懂了，但是很快忘记，这是因为并发知识还没有成体系。

1. 要让自己的知识成体系，一定要挖掘 Java SDK 并发包背后的设计理念
2. 分工、同步和互斥的全景图。
3. 对于某个具体的技术，我建议你探索它背后的理论本质，理论的应用面更宽，一项优秀的理论往往在多个语言中都有体现，在多个不同领域都有应用。

# 第一部分：并发理论基础 #

## 01 | 可见性、原子性和有序性问题：并发编程Bug的源头 ##

### 并发程序幕后的故事 ###

核心矛盾一直存在，就是CPU、内存、I/O设备三者的速度差异。

1. CPU增加了缓存，以均衡与内存的速度差异；
2. 操作系统增加了进程、线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异；
3. 编译程序优化指令执行时序，使得缓存能够得到更加合理地利用；

### 源头之一：缓存导致的可见性问题 ###

在单核时代，所有的线程都是在一颗CPU上执行，CPU缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个CPU的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。

一个线程对共享变量的修改，另外一个线程能够立刻看到，我们成为**可见性**

多核时代，每颗CPU都有自己的缓存，这时CPU缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的CPU上执行时，这些线程操作的是不同的CPU缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。

![单核时代](img/a07e8182819e2b260ce85b2167d446da.png)
![多核时代](img/e2aa76928b2bc135e08e7590ca36e0ea.png)

### 源头之二：线程切换带来的原子性问题 ###

操作系统允许某个进程执行一小段时间，例如50毫秒，过了50毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个50毫秒称为“时间片”。（在一个时间片内，如果一个进程进行IO操作，例如读个文件，这个时候该进程就可以把自己标记为“休眠状态”并且让出CPU使用权，待文件读进内存，操作系统会把休眠的进程唤醒，唤醒后的进程有机会重新获得CPU的使用权）

早期的操作系统基于进程来调度CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都共享一个内存空间的，所以线程切换成本更低。“任务切换”就是“线程切换”

多条CPU指令

count += 1，至少
1. 首先，需要把变量count从内存加载到CPU的寄存器；
2. 之后，再寄存器中执行+1操作；
3. 最后，将结果写入到内存（缓存机制导致可能写入的是CPU缓存而不是内存）

操作系统做任务切换，可以发生在任何一条**CPU指令**执行完，如果线程A在指令1执行完后做线程切换，线程A和线程B按照

我们把一个后者多个操作在CPU执行的过程不被中断的特性称为原子性

### 源头之三：编译优化带来的有序性问题 ###

双重检查创建单例对象，在获取实例getInstance()的方法中，我们首先判断instance是否为空，则锁定Singleton.class并再次检查isntance是否为空，如果为空则创建Singleton的一个实例。

	public class Singleton {
	  static Singleton instance;
	  static Singleton getInstance(){
	    if (instance == null) {
	      synchronized(Singleton.class) {
	        if (instance == null)
	          instance = new Singleton();
	        }
	    }
	    return instance;
	  }
	}

1. 分配一块内存M；
2. 在内存M上初始化Singleton对象；
3. 然后M的地址赋值给instance变量。

优化后的执行路径是：

1. 分配一块内存M；
2. 将M的地址赋值给instance变量；
3. 最后在内存M上初始化Singleton对象；

![64c955c65010aae3902ec918412827d8.png](img/64c955c65010aae3902ec918412827d8.png)

### 总结 ###

只要我们能够深刻理解可见性、原子性、有序性在并发场景下的原理，很多并发Bug都是可以理解、可以诊断的。

* 缓存：可见性问题
* 线程切换：原子性问题
* 编译优化：有序性问题

在采用一项技术的同时，一定要清除它带来的问题是什么，以及如何规避。

寄存器是共用的，A线程切换到B线程的时候，寄存器把操作A的相关内容会保存到内存中，切换回来的时候，会从内存把内容加载到寄存器。可以理解为每个线程都有自己的寄存器。

### 课后思考 ###

 32 位的机器上对 long 型变量进行加减操作存在并发隐患？

long型变量表示64位，在32位机器上，需要对long型变量进行加减操作的时候，需要时间片切换，引发原子性问题（线程切换带来的原子性问题）

## 02 | Java内存模型：看Java如何解决可见性和有序性问题 ##

因可见性、原子性、有序性导致的问题常常会违背我们的直觉，从而成为并发编程的 Bug 之源。这三者在编程领域属于共性问题。

### 什么是Java内存模型？ ###

解决可见性、有序性最直接的方法就是**禁用缓存和编译优化**，合理的方案应该是**按需禁用缓存以及编译优化**

Java内存模型规范了JVM如何提供按需禁用缓存和编译优化的方法，具体包括**volatile**、**synchronized**和**final**三个关键字，以及六项**Happens-Before规则**。

### 使用volatile的困惑 ###

volatile最原始的意义就是禁用CPU缓存(C语言，并不是Java特有的)。

	volatitle int x = 0，告诉编译器，对这个变量的读写，不能使用 CPU缓存，必须从内存中读取或者写入。


	// 以下代码来源于【参考1】
	class VolatileExample {
	  int x = 0;
	  volatile boolean v = false;
	  public void writer() {
	    x = 42;
	    v = true;
	  }
	  public void reader() {
	    if (v == true) {
	      // 这里x会是多少呢？
	    }
	  }
	}

Java1.5以前的版本会出现x=0的情况，变量x可能会被CPU缓存而导致可见性问题。

### Happens-Before规则 ###

前面一个操作的结果对后面操作是可见的。Happens-Before规则就是要保证线程之间的这种“心灵感应”。——Happens-Before约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守Happens-Before规则。

#### 1. 程序的顺序性规则 ####

第6行代码“x = 42;”
Happens-Before于第7行代码“v = true;”

符合单线程里面的思维；程序前面对某个变量的修改一定是对后续操作可见的。

#### 2. volatile变量规则 ####

对一个volatile变量的写操作，Happens-Before 于后续对这个 volatile 变量的读操作。。

“v=true” Happens-Before 读变量“v=true”

#### 3. 传递性 ####

A Happens-Before B，且B Happens-Before C，那么A Happens-Before C

* “x=42” Happens-Before写变量“v=true”，这是规则1的内容
* 写变量“v=true”Happens-Before读变量“v=true”，这是规则2的内容
* => “x=42” Happens-Before读变量“v=true”

“x=42” Happens-Before读变量“v=true”，如果线程B读到了“v=true”，那么线程A设置的“x=42”对线程B是可见的=>如果线程B能看到“x==42”

java.util.concurrent靠volatitle语义来搞定可见性的。

#### 4. 管程中锁的规则 ####

指对一个锁的解锁Happens-Before于后续对这个锁的加锁。

管程的定义：管程是一种通用的同步原语，在Java中指的是synchronized，synchronized是Java里对管程的实现。管程中的锁在Java里是隐式实现的。

	synchronzied (this) { // 此处自动加锁
		// x是共享变量，初始值=10
		if (this.x < 12) {
			this.x = 12;
		}
	} // 此处自动解锁

结合规则4——管程中锁的规则，可以理解：假设x的初始值是10，线程A完代码块后x的值会变成12（执行完自动释放锁），线程B进入代码块时，能看到线程A对x的写操作，也就是线程B能够看到x==12。

#### 5. 线程start()规则 ####

关于线程启动，指主线程A启动子线程B后，子线程B能够看到主线程在启动子线程B前的操作。

如果线程A调用线程B的start()方法（即在线程A中启动线程B），那么该start()操作Happens-Before于线程B中的任意操作。

	Thread B = new Thread(() -> {
		// 主线程调用B.start()之前
		// 所有对共享变量的修改，此处皆可见
		// 此例中，var == 77
	})
	// 此处对共享变量var修改
	var = 77；
	// 主线程启动子线程
	B.start();

#### 6. 线程join()规则 ####

线程等待的，它是指主线程A等待子线程B完成（主线程A通过调用子线程B的join()方法实现），当子线程B完成后（主线程A中join()方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对**共享变量**的操作。

如果在线程A中，调用线程B的join()并成功返回，那么线程B中的任意操作Happens-Before于该join()操作返回。

	Thread B = new Thread(()-> {
		// 此处对共享变量var修改
		var = 66;
	});
	// 例如此处对共享变量修改，
	// 则这个修改结果对线程B可见
	// 主线程启动子线程
	B.start();
	B.join();
	// 子线程所有对共享变量的修改
	// 主线程调用B.join()之后皆可见
	// 此例中，var==66

### 被我们忽视的final ###

final关键字

final修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲优化。

在1.5以后Java内存模型对final类型变量的重排进行了约束，目前直摇提供正确构造函数没有“逸出”，就不会出问题。（在构造函数里讲this赋值给了全局变量global.obj，这就是“逸出”）。

### 总结 ###

Time，Clocks，and the Ordering of Events is a Distributed System

在现实世界里，如果 A 事件是导致 B 事件的起因，那么 A 事件一定是先于（Happens-Before）B 事件发生的，这个就是 Happens-Before 语义的现实理解。在Java语言里面，Happens-Before的语义本质上是一种可见性，A Happens-Before B意味着A事件对B事件来说是可见得，无论A事件和B事件是否发生在同一个线程里。

Java内存模型主要分位两部分：

1. 面向你我这种编写并发程序的应用开发者
2. 面向JVM的实现人员

### 课后思考 ###

有一个共享变量abc，在一个线程里设置了abc的值abc=3，有哪些办法可以让其他线程能够看到abc==3？

	final int abc = 3;
	volatile int abc = 3;
	synchronized int abc = 3;

## 03 | 互斥锁（上）：解决原子性 ##

一个或者多个操作在CPU执行的过程中不被中断的特性，称为“原子性”。

#### 那原子性问题到底如何解决呢？ ####

原子性问题的源头是**线程切换**

操作系统做线程切换是依赖CPU中断的，所以禁止CPU发生中断就能够禁止线程切换。

在单核CPU场景下，同一时刻只有一个线程执行，禁止CPU中断，意味着操作系统不会重新调度线程，也就是静止了线程切换，获得CPU使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。但是在多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程执行在CPU-1上，一个线程执行在CPU-2上，此时禁止CPU中断，只能保证CPU上的线程连续执行，并不能保证同一时刻只有一个线程执行，如果这两个线程同时写long型变量高32位的话，就有可能出现诡异BUG。

“同一时刻只有一个线程执行”，“互斥”。能够对共享变量的修改是互斥的，无论是单核CPU还是多核CPU，都能保证原子性。

### 简易锁模型 ###

临界区

线程在进入临界区之前，首先尝试加锁lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则就等待，直到持有锁的线程解锁；持有锁的线程执行完成临界区的代码后，执行解锁unlock()。

PS：我们锁的是什么？我们保护的又是什么？

### 改进后的锁模型 ###

要保护资源R就得为它创建一把锁LR。针对这把锁LR，需要在进出临界区时添加锁操作和解锁操作。另外，在锁LR和受保护资源之间，特地用一条线做了关联，这个关联关联非常重要。很多并发

1. 把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护资源R
2. 其次，我们要保护资源R就得为它创建一把锁LR；
3. 针对这把锁LR，我们还需在进出临界区时添加上加锁操作和解锁操作。

### Java语言提供的锁技术：synchronized ###

锁是一种通用的技术方案，Java语言提供的synchronized关键字，就是锁的一种实现，synchronized关键字可以用来修饰方法，也可以用来修饰代码块。

	class X {
		synchronzied void foo() {
			//临界区
		}
		// 修饰静态方法
		synchronized static void bar() {
			//临界区
		}
		// 修饰代码块
		Object obj = new Object();
		void baz() {
			synchronzied(obj){
				// 临界区
			}
		}
	}

加锁lock和解锁unlock这两个操作，会被Java编译器在synchronized修饰符的方法或代码块前后自动加上。=>加锁lock和解锁unlock一定成对出现。

当修饰静态方法的时候，锁定的是当前类的Class对象，在上面的例子中就是Class X；当修饰非静态方法的时候，锁定的是当前实例对象this。

	class X {
		// 修饰静态方法
		synchronized(X.class) static void bar() {
			// 临界区
		}
	}
	
	class X {
		// 修饰非静态方法
		synchronized(this) void foo() {
			// 临界区
		}
	}

#### 用synchronized解决count += 1问题 ####

管程中锁的规则：对一个锁的Happens-Before于后续对这个锁的加锁。

管程，就是我们这里的synchronized，synchronized修饰的临界区是互斥的，也就是说同一时刻只有一个线程执行临界区的代码；而所谓“对一个锁解锁Happens-Before后续对这个锁的加锁”，指的是前一个线程的解锁操作对后一个线程的加锁操作可见，综合Happens-Before的传递性原则，我们得出前一个线程在临界区修改的共享变量（该操作的解锁之前），对后续进入临界区（该操作在加锁之后）的线程是可见的。

	class SafeCalc {
	  long value = 0L;
	  long get() {
	    return value;
	  }
	  synchronized void addOne() {
	    value += 1;
	  }
	}

多个线程同时执行addOne()方法，可见形势可以保证的，如果有1000个线程执行addOne()方法，最终value值一定是加到1000。

valued的值对get()可见性不可保证。需要对get()方法也添加synchronized。

	class SafeCalc {
	  long value = 0L;
	  synchronized long get() {
	    return value;
	  }
	  synchronized void addOne() {
	    value += 1;
	  }
	} 

get()方法和addOne()方法都需要访问value这个受保护的资源，这个资源用this这把锁来保护。线程要进入临界区get()和addOne()，必须先获得this这把锁。

### 锁和受保护资源的关系 ###

受保护资源和锁之间的关系关联是N:1的关系。

	class SafeCalc {
		static long value = 0L;
		synchronized long get() {
			return value;
		}
		synchronized static void addOne() {
			value += 1;
		}
	}

两个锁保护一个资源，这个受保护的资源就是静态变量value，两个锁分别是this和SafeCalc.class。由于临界区get()和addOne()是用两个锁保护的，因此两个临界区没有互斥关系，临界区addOne()对value的修改对临界区get()也没有可见性保证，导致并发问题。

![60551e006fca96f581f3dc25424226be.png](img/60551e006fca96f581f3dc25424226be.png)

### 总结 ###

互斥锁，在并发领域的知名度极高，只要有了并发问题，首先容易想到就是加锁，加锁能够保证执行临界区代码的互斥性。

临界区的代码是操作受保护资源的路径。加锁，但不是随便一把锁都能有效，所以必须深入分析锁定的对象和受保护资源的关系，综合考虑受保护资源的访问路径，多方面考量才能用好互斥锁。

synchronzied是Java在语言层面提供的互斥原语，其实Java里面还有很多其他类型的锁，但作为互斥锁，原理都是想通的：锁，一定要有一个要锁定的对象。

### 课后思考 ###

下面的代码用 synchronized 修饰代码块来尝试解决并发问题，你觉得这个使用方式正确吗？有哪些问题呢？能解决可见性和原子性问题吗？

	class SafeCalc {
	  long value = 0L;
	  long get() {
	    synchronized (new Object()) {
	      return value;
	    }
	  }
	  void addOne() {
	    synchronized (new Object()) {
	      value += 1;
	    }
	  }
	}

依然会有并发问题，这里的话，创建保护资源的锁obj1和obj2，用同样的锁分别对obj1和obj2，进行锁定，可见性没办法保证。

	加锁本质就是在锁对象的对象头中写入当前线程id，但是new object每次在内存中都是新对象，所以加锁无效。

## 04 | 互斥锁（下）：如何用一把锁保护多个资源 ##

受保护资源和锁之间合理的关联关系是N：1的关系。（可以用一把锁来保护多个资源，但是不能用多个锁来保护一个资源）

### 保护没有关联关系的多个资源 ###

用不同的锁对受保护资源进行精细化管理，能够提升性能。不同的资源用不同的锁保护，各自管各自的。

细粒度锁。

### 保护有关联关系的多个资源 ###

如果多个资源是有关联关系的，为题会比较复杂

	class Account {
	  private int balance;
	  // 转账
	  synchronized void transfer(
	      Account target, int amt){
	    if (this.balance > amt) {
	      this.balance -= amt;
	      target.balance += amt;
	    }
	  } 
	}

临界区内有两个资源，分别是转出账户的余额this.balanceh和转入账户的余额target.balance。

this可以保护自己的的余额this.balance，却保护不了别人的余额target.balance

![1ba92a09d1a55a6a1636318f30c155d8.png](img/1ba92a09d1a55a6a1636318f30c155d8.png)

假设有 A、B、C 三个账户，余额都是 200 元，我们用两个线程分别执行两个转账操作：账户 A 转给账户 B 100 元，账户 B 转给账户 C 100 元，最后我们期望的结果应该是账户 A 的余额是 100 元，账户 B 的余额是 200 元， 账户 C 的余额是 300 元。

我们假设线程 1 执行账户 A 转账户 B 的操作，线程 2 执行账户 B 转账户 C 的操作。这两个线程分别在两颗 CPU 上同时执行，那它们是互斥的吗？我们期望是，但实际上并不是。因为线程 1 锁定的是账户 A 的实例（A.this），而线程 2 锁定的是账户 B 的实例（B.this），所以这两个线程可以同时进入临界区 transfer()。同时进入临界区的结果是什么呢？线程 1 和线程 2 都会读到账户 B 的余额为 200，导致最终账户 B 的余额可能是 300（线程 1 后于线程 2 写 B.balance，线程 2 写的 B.balance 值被线程 1 覆盖），可能是 100（线程 1 先于线程 2 写 B.balance，线程 1 写的 B.balance 值被线程 2 覆盖），就是不可能是 200。

![a46b4a1e73671d6e6f1bdb26f6c87627.png](/img/a46b4a1e73671d6e6f1bdb26f6c87627.png)

### 使用锁的正确姿势 ###

锁能覆盖所有受保护资源

this是对象级别的锁，所以A对象和B对象都有自己的锁=>让A对象和B对象共享一把锁。我们把Account默认构造函数变为private，同时增加一个带Object lock参数的构造函数，创建Account对象时，传入相同的lock，这样所有的Account对象都会共享这个lock了。

	class Account {
	  private Object lock；
	  private int balance;
	  private Account();
	  // 创建Account时传入同一个lock对象
	  public Account(Object lock) {
	    this.lock = lock;
	  } 
	  // 转账
	  void transfer(Account target, int amt){
	    // 此处检查所有对象共享的锁
	    synchronized(lock) {
	      if (this.balance > amt) {
	        this.balance -= amt;
	        target.balance += amt;
	      }
	    }
	  }
	}

用Account.class作为共享的锁

	class Account {
	  private int balance;
	  private Account();
	  // 转账
	  void transfer(Account target, int amt){
	    // 此处检查所有对象共享的锁
	    synchronized(Account.class) {
	      if (this.balance > amt) {
	        this.balance -= amt;
	        target.balance += amt;
	      }
	    }
	  }
	}

![527cd65f747abac3f23390663748da7c.png](img/527cd65f747abac3f23390663748da7c.png)

### 总结 ###

关键是要分析多个资源之间的关系，如果资源之间没有关系，每个资源一把锁就可以了，如果资源之间有关联关系，就要选择一个粒度更大的锁，这个锁能够覆盖所有相关的资源。（梳理出有哪些访问路径，所有的访问路径都要设置合适的锁）

“原子性”的本质是什么？其实不是不可分割，不可分割只是外在表现，其本质是多个资源间有一致性的要求，操作的中间状态对外不可见。所以解决原子性问题，是要保证中间状态对外不可见。

### 课后思考 ###

private final Object xxxLock = new Object();，如果账户余额用 this.balance 作为互斥锁，账户密码用 this.password 作为互斥锁，你觉得是否可以呢？

## 05 | 一不小心就死锁了，怎么办？ ##

### 向现实世界要答案 ###

### 没有免费的午餐 ###

使用细粒度锁可以提高并行度，是性能优化的一个重要手段。但是有代价的，这个代价就是可能会导致死锁。

死锁：一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。

	假设线程 T1 执行账户 A 转账户 B 的操作，账户 A.transfer(账户 B)；同时线程 T2 执行账户 B 转账户 A 的操作，账户 B.transfer(账户 A)。当 T1 和 T2 同时执行完①处的代码时，T1 获得了账户 A 的锁（对于 T1，this 是账户 A），而 T2 获得了账户 B 的锁（对于 T2，this 是账户 B）。之后 T1 和 T2 在执行②处的代码时，T1 试图获取账户 B 的锁时，发现账户 B 已经被锁定（被 T2 锁定），所以 T1 开始等待；T2 则试图获取账户 A 的锁时，发现账户 A 已经被锁定（被 T1 锁定），所以 T2 也开始等待。于是 T1 和 T2 会无期限地等待下去，也就是我们所说的死锁了。

### 如何预防死锁 ###

1. 互斥，共享资源X和Y只能被一个线程占用；
2. 占有且等待，线程T1已经取得共享资源X，在等待共享资源Y的时候，不释放共享资源X；
3. 不可抢占，其他线程不能强行抢占线程T1占有的资源；
4. 循环等待

也就是说只要我们破坏其中一个，就可以避免死锁的发生。

1. 对于“占用且等待”这个条件，可以一次性申请所有的资源
2. 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了
3. 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的实偶可以先申请资源资源序号小，再申请资源序号大的，这样线性化后自然就不存在循环了。

#### 1. 破坏占用且等待条件 ####

破坏这个条件，可以一次性申请所有资源。

“同时申请”这个操作是一个临界区，需要一个角色（Java里面的类）来管理这个临界区，把这个角色定位为Allocator，它有两个重要功能，分别是：同时申请资源apply()和同时释放资源free()。

账户Account类里面持有一个Allocator的单例（必须是单例，只能由一个人来分配）。当账户Account在执行转账操作的时候，首先向Allocator同时申请转出账户和转入账户这两个资源，成功后再锁定这两个资源；当转账操作执行完，释放锁之后，通知

#### 2. 破坏不可抢占条件 ####

#### 3. 破坏循环等待条件 ####

### 总结 ###

利用现实世界的模型来构思解决方案

评估一下操作成本，从中选择一个成本最低的方案。

### 课后思考 ###

## 06 | 用“等待-通知”机制优化循环等待 ##

等待-通知机制

### 尽量使用 notifyAll() ###

### 总结 ###

synchronized 配合 wait()、notify...

### 课后思考 ###

wait()方法和sleep()方法

# 07 | 安全性、活跃性以及性能问题 #

### 安全性问题 ###

锁

### 活跃性问题 ###

死锁，活锁和饥饿

### 性能问题 ###

### 总结 ###

* 微观上涉及到原子性问题、可见性问题和有序性问题
* 宏观则表现为安全性、活跃性以及性能问题

### 课后思考 ###


# 08 | 管程：并发编程的万能钥匙 #

### 什么是管程 ###

管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。

管程：指的是管理共享变量以及共享变量的操作过程，让他们支持并发。

### MESA模型 ###

管程的发展史：

1. Hasen模型
2. Hoare模型
3. MESA模型

# 08 | 管程：并发编程的万能钥匙 #

# 09 | Java线程（上）：Java线程的生命周期 #

### 通用的线程生命周期 ###

### Java中线程的生命周期 ###

1. NEW（初始化状态）
2. RUNNABLE（可运行/运行状态）
3. BLOCKED（阻塞状态）
4. WAITING（无时限等待）
5. TIMED_WAITING（有时限等待）
6. TERMINATED（终止状态）

#### 1. RUNNABLE与BLOCKED的状态转换 ####

#### 2. RUNNABLE与WAITING的状态转换 ####

#### 3. RUNNABLE与TIMED_WAITING的状态转换 ####

1. 调用带超时参数的Thread.sleep(long millis)方法；
2. 获得synchronized隐式锁的线程，调用带超时参数的Object.wait(long timeout)方法
3. 调用带超时参数的Thread.join(long millis)方法；
4. 调用带超时参数的LockSupport.parkNanos(Object blocker, long deadline)方法；
5. 调用带超时参数的LockSupport.partUntil(long deadline)方法。

#### 4. 从NEW到RUNNABLE状态 ####

#### 5. 从RUNNABLE到TERMINATED状态 ####

* stop()
* interrupt()

### 总结 ###

### 课后思考 ###

# 10 | Java线程（中）：创建多少线程才是合适的？ #

### 为什么要使用多线程？ ###

延迟和吞吐量

### 多线程的应用场景 ###

### 创建多少线程合适？ ###



### 总结 ###

将硬件的性能发挥到极致

### 课后思考 ###



# 11 | Java线程（下）：为什么局部变量是线程安全的？ #

### 方法是如何被执行 ###

通过CPU的堆栈寄存器。CPU支持一种栈结构。因为栈和方法调用相关，因此被称为调用栈。

每个方法在调用栈里都有自己的独立空间，称为帧栈。每个栈帧里都有对应方法需要的参数和返回地址。当调用方法时，会创建新的栈帧，并压入调用栈；当方法返回时，对应的栈帧就会被自动弹出。也就是说，栈帧和方法是同生同死的。

Java语言虽然是靠虚拟机解释执行的，但是方法调用也是利用栈结构解决的。

### 局部变量存哪里？ ###

局部变量的作用域是方法内部，也就是说方法执行完，局部变量就没用了，局部变量和方法应该同生共死。调用栈的栈帧就是和方法同生共死的，所以局部变量放到调用栈那儿是相当的合理。

局部变量就是放到调用栈里的。

局部变量和方法同生共死的，一个变量如果想要跨越方法的边界，就必须创建在堆中。

### 调用栈与线程 ###

每个线程都有自己独立的调用栈。

Java方法里面的局部变量是否存在并发问题？一点问题都没有，因为每个线程都有自己的调用栈，局部变量保存在线程各自的调用栈里面，不会共享，所以自然也就没有并发问题。

没有共享，就没有伤害。

### 线程封闭 ###

方法里的局部变量，因此不会和其他线程共享，所以没有并发问题。

线程封闭，仅在单线程内访问数据。

在JDBC规范里并没有要求这个Connection必须是线程安全的。数据库连接池通过线程封闭技术，保证一个Connection一旦被一个线程获取之后，在这个线程关闭Connection之前的这段时间里，不会再分配给其他线程，从而保证了Connection不会有并发问题。

### 总结 ###

研究原理性的东西、通用的东西。

### 课后思考 ###

常听人说，递归调用太深，可能导致栈溢出。

# 12 | 如何用面向思想写好并发程序？ #

在Java语言中，面向对象思想能够让并发编程变得更简单。

封装共享变量、识别共享变量间的约束条件和制定并发访问策略这三方面下手

### 一、封装共享变量 ###

面向对象思想里面有一个很重要的特性是**封装**，封装的通俗解释就是讲属性和实现细节封装在对象内部，外界对象只能通过目标对象提供的公共方法来间接访问这些属性。

利用面向对象思想写并发程序的思想，将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略

对于不会发生变化的共享变量，建议使用final关键字来修饰。

### 二、识别共享变量间的约束条件 ###

识别共享变量间的约束条件非常重要。因为这些约束条件，决定并发访问策略。

### 三、制定并发访问策略 ###

1. 避免共享：避免共享的技术主要是利于线程本地存储以及为每个任务分配独立的线程。
2. 不变模式：这个在Java领域应用的很少，但在其他领域却有着广泛的应用，例如Actor模式、CSP模式以及函数式编程的基础都是不变模式。
3. 管程及其他同步工具：Java领域万能的解决方案是管程，但是对于很多特定的场景，使用Java并发包提供的读写锁、并发容器等同步工具会更好。

### 总结 ###

利用面向对象思想编写并发程序

1. 利用面向对象里的封装特性
2. 面对共享变量进行封装，要避免“逸出”，所谓“逸出”就是共享变量逃逸到对象的外面。

### 课后思考 ###

类SafeVM不满足库存下限要小于库存上限这个约束条件，修改让它能够在并发条件下满足库存下限要小于库存上限这个约束条件

### 延伸阅读 ###

# 13 | 理论基础模块热点问题答疑 #

### 1. 用锁的最佳实践 ###

### 2. 锁的性能要看场景 ###

### 3. 竞态条件需要格外关注 ###

### 4. 方法调用是先计算参数 ###

### 5. InterruptedException异常处理需小心 ###

# 第二部分：并发工具类 #

# 14 | Lock和Condition（上）：隐藏在并发包中的管程 #

1. 互斥：同一时刻只允许一个线程访问共享资源。
2. 同步：线程之间如何通信、写作。

Java SDK并发包通过Lock和Condition两个接口来实现管程，其中Lock用于解决互斥问题，Condition用于解决同步问题。

### 再造管程的理由 ###

synchronized申请资源的时候，如果申请不到，线程直接进入阻塞状态，二线程进入阻塞状态，也释放不了线程已经占有的资源。

1. 能够响应中断。synchronized的问题是，持有锁A后，如果尝试获取锁B失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发生中断信号的时候，能够唤醒它，那么它就有机会释放曾经持有的锁A。这样就破坏了不可抢占条件了。
2. 支持超时。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经的持有的锁，这样也能破坏不可抢占条件。
3. 非阻塞地获取锁。如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。

	// 支持中断的API
	void lockInterruptibly() throws InterruputedException;
	// 支持超时的API
	boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
	// 支持非阻塞获取锁的API
	boolean tryLock();

### 如何保证可见性 ###

### 什么是可重入锁 ###

所谓可重入锁，顾名思义，指的是线程可以重复获取同一把锁。

### 公平锁与非公平锁 ###

在使用ReetrantLock时候，有两个构造函数，一个是无参构造函数，一个是传入fail参数的构造函数。fair参数代表的是锁的公平策略，如果传入true就标识需要构造一个公平锁，反之则表示要一个非公平锁。

	// 无参构造函数：默认非公平锁
	public ReetrantLock() {
		sync = new NonfairSync();
	}
	// 根据公平策略参数创建锁
	public ReetrantLock(boolean fair) {
		sync = fair ? new FairSync() : new NonfairSync();
	}
	
	
### 用锁的最佳实践 ###

Java并发编程：设计原则与模式

1. 永远只在更新对象的成员变量时加锁
2. 永远只在访问可变的成员变量时加锁
3. 永远不在调用其他对象的方法时加锁

### 总结 ###





# 15 | Lock和Conndition（下）：Dubbo如何用管程实现异步转同步 #



# 结束语 #

## 结束语 | 十年之后，初心依旧 ##

# 用户故事 #






