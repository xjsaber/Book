# MySQL实战45讲 #

# 开篇词 #

## 开篇词 | 这一次，让我们一起来搞懂MySQL ##

平时使用数据库时高频出现的知识，如事务、索引、锁等内容构成专栏的主线。


点->线->面，形成自己的MySQL知识网络

# 基础篇 #

## 01 | 基础架构：一条SQL查询语句是如何执行的？ ##

mysql> select * from T where ID = 10;

![0d2070e8f84c4801adbfa03bda1f98d9](img/0d2070e8f84c4801adbfa03bda1f98d9.png)

MySQL分为Server层和存储引擎层两部分。

Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大部分核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分。

### 连接器 ###

1. 先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。`mysql -h$ip -P$port -u$user -p`（连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。）

建立连接的过程通常比较复杂的，所以在使用中要尽量减少建立连接的动作，也尽量使用长连接。但全部使用长连接后，有时候MySQL占用内存涨得特别快，因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。=>内存占用太大，被系统强行杀掉（OOM）=>MySQL异常重启

解决方案：

1. 定期断开长连接。使用一段时间后，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
2. 如果是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

    wait_timeout默认值是8小时

### 查询缓存 ###

*但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。*

查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。

8.0以后没有这块功能。

### 分析器 ###

如果没有命中查询缓存

1. MySQL需要对SQL语句做解析
2. 词法分析， `select * from T where ID = 10;` 比如select，识别出来是一个查询语句，把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。
3. 语法分析，语法分析器会根据语法判断，判断是否满足MySQL语法。

### 优化器 ###

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：

	mysql> select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;

* 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。
* 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。

逻辑结果一样，但执行的效率不同，优化器的作用就是决定选择使用哪个方案。

优化器阶段完成后，这个语句的执行方案就确定下来了。

### 执行器 ###

执行器阶段，开始执行语句。

开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。

如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：

1. 调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；
2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。

引擎扫描行数跟 rows_examined 并不是完全相同的。

### 小结 ###

### 精选留言 ###

#### Q ####

如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？

#### A ####

* Oracle会在分析阶段判断语句是否正确，表是否存在，列是否存在等。

* 对权限的检查不在优化器之前做，，SQL语句要操作的表不只是SQL字面上那些。比如如果有个触发器，得在执行器阶段（过程中）才能确定。优化器阶段前是无能为力的。

分析器，优化器是对SQL语句进行择优处理，执行器需要判断选取表中的权限。

## 02 | 日志系统：一条SQL更新语句是如何执行的？ ##

一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。

查询语句对策那一套流程，更新语句也是同样走一遍。

1. 连接器：执行语句前要先连接数据库
2. 查询缓存：一个表上有更新的时候，跟这个表有关的查询缓存会失效。所以这条语句就会把表T上所有缓存结果都清空（不建议使用查询缓存的原因）
3. 分析器：通过词法和语法解析知道这是一条更新语句
4. 优化器：使用ID索引
5. 执行器：负责具体执行，找到这一行，更新

### 重要的日志模块：redo log ###

WAL的全称是Write-Ahead Logging，关键点是先写日志，再写磁盘。

当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存。InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面（系统比较空闲的时候处理）。如果写满了，需要腾出空间才行。

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写。

![16a7950217b3f0f4ed02db5db59562a7.png](img/16a7950217b3f0f4ed02db5db59562a7.png)

* write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。
* checkpoint是当前要擦除的位置，也是往后推移并且循环，擦除记录前要把记录更新到数据文件。
* write pos和checkpoint之间的是“粉版”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

crash-safe：因为redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失

### 重要的日志模块：binlog ###

MySQL整体来看，有两块

1.  Server 层，主要做的是MySQL功能层面的事情
2.  引擎层，负责存储相关的具体事宜

---

1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程：`mysql> update T set c=c+1 where ID=2;`

![2e5bff4910ec189fe1ee6e2ecc7b4bbe.png](img/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)

1. 
	* 执行器：执行器先找引擎取 ID=2 这一行。
	* 引擎：ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器：执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 
3. 引擎：引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器：执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 引擎：执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

redo log的写入拆成了两个步骤：prepare和commit，两阶段提交

### 两阶段提交 ###

两阶段提交的原因是为了让两份日志的逻辑一致。=>怎样让数据库恢复到半个月内任意一秒的状态？

1. binlog会记录所有的逻辑操作
2. 系统定期做整库备份
3. 找到最近一天的全量备份，然后通过这个备份恢复到临时库
4. 从备份时间开始，将备份的binlog依次取出，重新进行到误操作时间点的那个时候

如果不使用两阶段提交。

1. 先写 redo log 后写 binlog。
	* redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。
	* 但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。
2. 先写 binlog 后写 redo log。
	* 如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。

不只是操作，还有扩容的时候。通常的做法是用全量备份加上应用 binlog 来实现的。

简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

### 小结 ###

* 两个日志，即物理日志redo log和逻辑日志binlog。
* redo log用于保证crash-safe能力。
	*  innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。
* sync_binlog  
	* sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 
* 与 MySQL 日志系统密切相关的“两阶段提交”：两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。   

前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？

### 精选留言 ###

#### Q ####

说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？

#### A ####

一天一备，只需要根据前一天的redo log的记录把binarylog 复现一遍即可，不容易无操作，隔断时间比较少。但这样redolog的记录会比较大。

Binlog两种模式

1. statement格式的话是记sql语句
2. row格式会记录行的内容，记两条，更新前和更新后的内容

redo是物理的，binlog是逻辑的；现在由于redo是属于InnoDB引擎，所以必须要有binlog（可以使用别的引擎）保证数据库的一致性，必须要保证2份日志一致。使用的2阶段式提交；其他感觉像事务，不是成功就是失败，不能让中间环节出现，也就是一个成功，一个失败。

#### Q ####

只用InonoDB引擎的时候还保留Binlog这种设计的原因

#### A ####

1. redolog只有InnoDB有，别的引擎没有
2. redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。

## 03 | 事务隔离：为什么你改了我还看不见？ ##

事务就是要保证一组数据库操作，要么全部成功，要么全部失败。

### 隔离性与隔离级别 ###

ACID（Atomicity，Consistency，Isolation，Durability，即原子性、一致性、隔离性和持久性）

当数据库上有多个事务同时执行的时候=>可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题=>有了“隔离级别”的概念，去解决这些问题

#### 隔离级别 ####

隔离级别越高，效率越低=>需要找到平衡点

SQL标准的事务隔离级别：

1. 读未提交（read uncommitted）：一个事务还没提交时，它做的变更就能被别的事务看到。
2. 读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到。
3. 可重复读（repeatable read）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
4. 串行化（serializable）：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

![7dea45932a6b722eb069d2264d0066f8](img/7dea45932a6b722eb069d2264d0066f8.png)

根据事务隔离级别的不同，V1、V2、V3返回值也会分别不同。

* 读未提交：V2、V3=2，B的事务还没提交，但做个变更就能被别的事务看到，所以V1也是2
* 读提交：V2、V3=2，事务 B 的更新在提交后才能被 A 看到，所以V1也是1
* 可重复读：事务在执行期间看到的数据前后必须是一致的，所以v1，v2=1，v3=2
* 串行化：则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。v1、v2值是1，v3的值是2

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。

* “读提交”隔离级别：在每个 SQL 语句开始执行的时候创建的
* “可重复读”隔离级别：在事务启动时创建的，整个事务存在期间都用这个视图

“读未提交”隔离级别：直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。

	show variables like 'transaction_isolation'

根据业务场景选择不同的隔离级别

### 事务隔离实现 ###

假设一个值从1被按顺序改成2、3、4，在回滚日志会有如下的记录：

![d9c313809e5ac148fc39feff532f0fee](img/d9c313809e5ac148fc39feff532f0fee.png)

回滚日志删除条件：系统判断，当前没有事务再需要用到这些回滚日志时，回滚日志会被删除。当系统里没有比这个回滚日志更早的 read-view 的时候会被正式清除。

在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。（我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。）还有占用锁资源，拖垮整个库的问题。

### 事务的启动方式 ###

MySQL 的事务启动方式有以下几种：

1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。

在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。

information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

	select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started)) > 60

### 小结 ###

1. 介绍了 MySQL 的事务隔离级别的现象和实现
2. 根据实现原理分析了长事务存在的风险
3. 如何用正确的方式避免长事务

我给你留一个问题吧。你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？

## 04 | 深入浅出牵引（上） ##

索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。对于数据库的表而言，索引其实就是它的“目录”。

### 索引的常见模型 ###

索引的出现是为了提高查询效率，三种常见的模型：

1. 哈希表
2. 有序数组
3. 搜索树

#### 哈希表 ####

哈希表是一种以键 - 值（key-value）存储数据的结构，输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。

多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。
有序

哈希表这种结构适用于只有等值查询的场景

#### 有序数组 ####

有序数组在等值查询和范围查询场景中的性能就都非常优秀。

#### 搜索树 ####

#### 实战 ####

在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。

### InnoDB的索引模型 ###

在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。

每一个索引在 InnoDB 里面对应一棵 B+ 树。

* 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。
* 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。

#### 基于主键索引和普通索引的查询有什么区别？ ####

* 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；
* 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。
* 基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

### 索引维护 ###

B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。

自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。

显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

从性能和存储空间方面考量，自增主键往往是更合理的选择。

1. 只有一个索引；
2. 该索引必须是唯一索引
3. 类似典型的KV场景
4. “尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树

### 小结 ###

InnoDB采用的B+树结构，以及InnoDB要选择B+树的原因。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。

## 05 | 深入浅出牵引（下） ##

`select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？

    mysql> create table T (
    ID int primary key,
    k int NOT NULL DEFAULT 0, 
    s varchar(16) NOT NULL DEFAULT '',
    index k(k))
    engine=InnoDB;
    
    insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');

这条SQL查询查询语句的执行流程：

1. 在k索引树上找到k=3的记录，取得ID=300;
2. 再到ID索引树查到ID=300对应的R3;
3. 在k索引树取下一个值k=5，取得ID=500;
4. 再回到ID索引树查到ID=500对应的R4;
5. 在k索引树取下一个值k=6，不满足条件，循环结束。

回到主键索引树搜索的过程，我们称为回表。


### 覆盖索引 ###

由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

索引字段的维护总是有代价的。在建立冗余索引来支持覆盖索引时就需要权衡考虑了。

### 最左前缀原则 ###

B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。用(name, age)这个联合索引来分析。

在建立联合索引的时候，如何安排索引内的字段顺序。

1. 如果通过调整顺序，可以少维护一个索引，那么这个索引往往就是需要优先考虑采用。
	* 既有联合查询，又有基于a、b各自的查询：只有b的语句，是无法使用（a，b）这个联合索引，这时候不得不维护另外一个索引，同时维护（a，b）、（b）这两个索引
2. 考虑的原则就是空间

### 索引下推 ###

	mysql> select * from tuser where name like '张%' and age=10 and ismale=1;

* 在MySQL5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。
	* 在(name, age)索引里面，InnoDB并不会去看age的值，只是按顺序把“name第一个字是‘张’”的记录一条条取出来回表，需要回表4次。 
* MySQL5.6引入的索引下推优化（index condition pushdown），可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。
	*  InnoDB在（name， age）索引内部就判断了age是否等于10，对于不等于10的记录，直接判断并跳过。只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。

### 小结 ###

数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。


## 06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍 ##

数据库锁设计的初衷是处理并发问题，作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。

*根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。*

### 全局锁 ###

全局锁就是对整个数据库实例加锁。通过 Flush tables with read lock(FTWRL) 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。unlock tables解锁。

*全局锁的典型使用场景是，做全库逻辑备份。*（整库每个表都select出来存成文本）。

* 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
* 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。

如果不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。

*一致性读是好，但前提是引擎要支持这个隔离级别。*对于MyISAM不支持事务的引擎，备份过程中有更新，总是只能取到最新的数据，破坏了备份的一致性。——FTWRL命令

single-transaction方法只适用于所有的表适用事务引擎的库。如果有的表适用了不支持事务的引擎，那么备份就只能通过FTWRL方法。（DBA要求业务开发人员适用InnoDB代替MyISAM的原因之一）。

*既然要全库只读，为什么不使用 set global readonly=true 的方式呢？*

1. 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。
2. 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

### 表级锁 ###

MySQL 里面表级别的锁有两种：

1. 表锁：`lock tabels...read/write`。
	*  可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象
2. 元数据锁（meta data lock，MDL)。

对于InnoDB支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面很大。

*另一类表级的锁是 MDL（metadata lock)*。MDL不需要显式使用，在访问一个表的时候会自动加上。

MySQL5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加上MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

* 读锁之间不互斥，因此可以有多个线程同时对一张表增删改查。
* 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行玩才能开始执行。

给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。

#### 如何安全地给小表加字段？ ####

1. 解决长事务，事务不提交，就会一直占着MDL锁。
	* 在 MySQL 的 information_schema 库的 innodb_trx 表中，查到当前执行中的事务。
	* 如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。
2. 变更的表是一个热点表（数据量不大，但是上面的请求很频繁，不得不加字段）
	* kill未必管用，新的请求马上就来了
	* 在alert table语句里面设定等待时间（如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃）
	* repeat

具体语句：

	ALTER TABLE tbl_name NOWAIT add column ...
	ALTER TABLE tbl_name WAIT N add column ... 

### 小结 ###

介绍了 MySQL 的全局锁和表级锁

全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数。

表锁一般是在数据库引擎不支持行锁的时候才会被用到的。lock tables

* 要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；
* lock tables 和 unlock tables 改成 begin 和 commit

## 07 | 行锁功过：怎么减少行锁对性能的影响？ ##

MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。

InnoDB 的行锁，以及如何通过减少锁冲突来提升业务并发度。行锁就是针对数据表中行记录的锁。比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。

### 死锁和死锁检测 ###

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要就立刻释放，而是要等到事务结束才释放。这个就是两阶段锁协议。所以*如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放*。

### 死锁和死锁检测 ###

当并发系统中不同线程出现循环资源依赖，涉及的线程在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

1. 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

在InnoDB中，innodb_lock_wait_timeout的默认值是50s（如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行）——对于在线服务来说，这个等待时间往往是无法接受的。

### 小结 ###

MySQL的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。

1. 

## 08 | 事务到底是隔离的还是不隔离的？ ##

	mysql> CREATE TABLE `t` (
	  `id` int(11) NOT NULL,
	  `k` int(11) DEFAULT NULL,
	  PRIMARY KEY (`id`)
	) ENGINE=InnoDB;
	insert into t(id, k) values(1,1),(2,2);

在MySQL里，有两个“视图”的概念：

* view，是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是`create view...`，而它的查询方法与表一样。
* InnoDB在实现MVCC时用到的一致性读视图，即consitent read view，用于支持RC（Read Committed，读操作）和RR（Repeatable Read，可重复读）隔离级别的实现。

没有物理结构，作用的是事务执行期间用来定义“我能看到什么数据”。

### “快照”在MVCC里怎么工作的？ ###

在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。

* transaction id，InnoDB 里面每个事务有一个唯一的事务 ID，在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。
* row trx_id，每行数据也都是有很多版本的。每次事务更新数据的时候，都会生成一个新的数据版本；旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到；数据表中的一行记录，其实可能有多个版本（row），每个版本有自己的row_trx_id。

#### undo log在哪呢？ ####

1. 已提交的事务或者当前事务自己省车功能的，这个数据是可见的
2. 将来启动的事务生成的，是肯定不可兼得
3. 未提交事务集合
	* 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
	* 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 

*InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。*

### 更新逻辑 ###

事务 B 的 update 语句，如果按照一致性读，好像结果不对哦？你看图 5 中，事务 B 的视图数


