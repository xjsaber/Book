# Spark实战 #

# 第1部分 #

## 第一章 Apache Spark简介 ##

### 1.1 什么是Spark ###

#### 1.1.1 Spark革命 ####

#### 1.1.2 MapReduce的缺点 ####

#### 1.1.3 Spark带来了什么有价值的东西 ####

Spark的核心概念是内存中的执行模式，可以将内存中的作业数据缓存，而不是像MapReduce一样从磁盘中取出。

在MapReduce的情况下，需要将这3个阶段的结果存储在磁盘（HDFS）上，每个后续阶段将从磁盘读取前一个结果。通过Spark，用户可以找到所有顶点之间的最短路径并缓存数据于内存中。下一个阶段可以使用内存中的数据，为每个顶点找到最远点距离，并缓存其结果。最后一个阶段可以通过这个最终的缓存数据，找到具有最小点距离的顶点。

1. Spark的易用性
2. Spark作为一个统一的平台
3. Spark反面模式

### 1.2 Spark组件 ###

#### 1.2.1 Spark Core ####

### 1.4 Spark生态系统 ###

### 1.5 设置spark-in-action VM ###

### 1.6 总结 ###

* Apache Spark是一种令人兴奋的新技术


## 第2章 Spark基础 ##

### 2.1 使用spark-in-action VM ###

#### 2.1.1 复制spark in Action GitHub存储库 ####

#### 2.1.2 找到Java ####

#### 2.1.3 使用虚拟机的Hadoop安装 ####

#### 2.1.4 检查虚拟机的Spark安装 ####

### 2.2 用Spark shell编写第一个Spark程序 ###

#### 2.2.1 启动Spark shell ####

#### 2.2.2 第一个Spark代码示例 ####

#### 2.2.3 弹性分布式数据集的概念 ####

RDD是Spark中的基本抽象。代表一个元素的集合具有：

* 不可变（只读）
* 弹性（容错）
* 分布式（数据集扩展到多个节点）

### 2.3 基本RDD行动和转换操作 ###

#### 2.3.1 使用map转换 ####

#### 2.3.2 使用distinct和flatMap转换 ####

#### 2.3.3 使用sample、take和takeSample操作获取RDD的元素 ####

### 2.4 Double RDD函数 ###

## 第3章 编写Spark应用程序 ##

### 3.1 在Eclipse中生成一个新的Spark项目 ###

### 3.2 开发应用程序 3###



## 第4章 深入Spark API ##

### 4.1 使用键值对RDD ###

#### 4.1.1 创建键值对RDD ####



#### 4.1.2 键值对RDD的基本功能 ####

**1. 获取键和值**

**2. 计数每个键的值**
